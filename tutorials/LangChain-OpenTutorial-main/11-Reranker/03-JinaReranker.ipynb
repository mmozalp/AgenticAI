{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "635d8ebb",
      "metadata": {},
      "source": [
        "# JinaReranker\n",
        "\n",
        "- Author: [hyeyeoon](https://github.com/hyeyeoon)\n",
        "- Peer Review: \n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/01-Basic/08-Runnable.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/01-Basic/08-Runnable.ipynb)\n",
        "\n",
        "## Overview\n",
        "\n",
        "`Jina Reranker` is a document re-ranking and compression tool that reorders retrieved documents or results to prioritize the most relevant items. It is primarily used in information retrieval and natural language processing (NLP) tasks, designed to extract critical information more quickly and accurately from large datasets.\n",
        "\n",
        "---\n",
        "\n",
        "**Key Features**\n",
        "\n",
        "- Relevance-based Re-ranking\n",
        "\n",
        "    Jina Reranker analyzes search results and reorders documents based on relevance scores. This ensures that users can access more relevant information first.\n",
        "\n",
        "- Multilingual Support\n",
        "\n",
        "    Jina Reranker supports multilingual models, such as `jina-reranker-v2-base-multilingual`, enabling the processing of data in various languages.\n",
        "\n",
        "- Document Compression\n",
        "\n",
        "    It selects only the top N most relevant documents (`top_n`), compressing the search results to reduce noise and optimize performance.\n",
        "\n",
        "- Integration with LangChain\n",
        "\n",
        "    Jina Reranker integrates seamlessly with workflow tools like LangChain, making it easy to connect to natural language processing pipelines.\n",
        "\n",
        "---\n",
        "\n",
        "**How It Works**\n",
        "\n",
        "- Document Retrieval\n",
        "\n",
        "    The base retriever is used to fetch initial search results.\n",
        "\n",
        "- Relevance Score Calculation\n",
        "\n",
        "    Jina Reranker utilizes pre-trained models (e.g., `jina-reranker-v2-base-multilingual`) to calculate relevance scores for each document.\n",
        "\n",
        "- Document Re-ranking and Compression\n",
        "\n",
        "    Based on the relevance scores, it selects the top N documents and provides reordered results.\n",
        "\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [Jina Reranker](#Jina-Reranker)\n",
        "- [Performing Re-ranking with JinaRerank](#Performing-re-ranking-with-JinaRerank)\n",
        "\n",
        "### References\n",
        "\n",
        "- [LangChain Documentation](https://python.langchain.com/docs/how_to/lcel_cheatsheet/)\n",
        "- [Jina Reranker](https://jina.ai/reranker/)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6c7aba4",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details.\n",
        "**Issuing an API Key for JinaReranker**\n",
        "- Add the following to your .env file\n",
        "    >JINA_API_KEY=\"YOUR_JINA_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "21943adb",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "!pip install langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f25ec196",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain\",\n",
        "        \"langchain_core\",\n",
        "        \"langchain_openai\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "690a9ae0",
      "metadata": {},
      "source": [
        "You can also load the `OPEN_API_KEY` from the `.env` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4f99b5b6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7f9065ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set local environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"03-JinaReranker\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa00c3f4",
      "metadata": {},
      "source": [
        "## Jina Reranker\n",
        "\n",
        "- Load data for a simple example and create a retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "69cb77da",
      "metadata": {},
      "outputs": [],
      "source": [
        "def pretty_print_docs(docs):\n",
        "    print(\n",
        "        f\"\\n{'-' * 100}\\n\".join(\n",
        "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74660e4d",
      "metadata": {},
      "source": [
        "- A text document is loaded into the system.\n",
        "\n",
        "- The document is split into smaller chunks for better processing.\n",
        "\n",
        "- `FAISS` is used with `OpenAI embeddings` to create a retriever.\n",
        "\n",
        "- The retriever processes a query to find and display the most relevant documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "3d367787",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 1:\n",
            "\n",
            "Word2Vec\n",
            "Definition: Word2Vec is a technique in NLP that maps words to a vector space, representing their semantic relationships based on context.\n",
            "Example: In a Word2Vec model, \"king\" and \"queen\" are represented by vectors located close to each other.\n",
            "Related Keywords: Natural Language Processing (NLP), Embedding, Semantic Similarity\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "Embedding\n",
            "Definition: Embedding is the process of converting textual data, such as words or sentences, into low-dimensional continuous vectors that computers can process and understand.\n",
            "Example: The word \"apple\" can be represented as a vector like [0.65, -0.23, 0.17].\n",
            "Related Keywords: Natural Language Processing (NLP), Vectorization, Deep Learning\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "VectorStore\n",
            "Definition: A VectorStore is a system designed to store data in vector format, enabling efficient retrieval, classification, and analysis tasks.\n",
            "Example: Storing word embedding vectors in a database for quick access during semantic search.\n",
            "Related Keywords: Embedding, Database, Vectorization\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 4:\n",
            "\n",
            "TF-IDF (Term Frequency-Inverse Document Frequency)\n",
            "Definition: TF-IDF is a statistical measure used to evaluate the importance of a word within a document by considering its frequency and rarity across a corpus.\n",
            "Example: Words with high TF-IDF values are often unique and critical for understanding the document.\n",
            "Related Keywords: Natural Language Processing (NLP), Information Retrieval, Data Mining\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 5:\n",
            "\n",
            "GPT (Generative Pretrained Transformer)\n",
            "Definition: GPT is a generative language model pre-trained on vast datasets, capable of performing various text-based tasks. It generates natural and coherent text based on input.\n",
            "Example: A chatbot generating detailed answers to user queries is powered by GPT models.\n",
            "Related Keywords: Natural Language Processing (NLP), Text Generation, Deep Learning\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 6:\n",
            "\n",
            "Tokenizer\n",
            "Definition: A tokenizer is a tool that splits text data into tokens, often used for preprocessing in natural language processing tasks.\n",
            "Example: The sentence \"I love programming.\" is tokenized into [\"I\", \"love\", \"programming\", \".\"].\n",
            "Related Keywords: Tokenization, Natural Language Processing (NLP), Syntax Analysis.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 7:\n",
            "\n",
            "LLM (Large Language Model)\n",
            "Definition: LLMs are massive language models trained on large-scale text data, used for various natural language understanding and generation tasks.\n",
            "Example: OpenAI's GPT series is a prominent example of LLMs.\n",
            "Related Keywords: Natural Language Processing (NLP), Deep Learning, Text Generation\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 8:\n",
            "\n",
            "Transformer\n",
            "Definition: A Transformer is a type of deep learning model widely used in natural language processing tasks like translation, summarization, and text generation. It is based on the Attention mechanism.\n",
            "Example: Google Translate utilizes a Transformer model for multilingual translation.\n",
            "Related Keywords: Deep Learning, Natural Language Processing (NLP), Attention mechanism\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 9:\n",
            "\n",
            "Semantic Search\n",
            "Definition: Semantic search is a search technique that understands the meaning of a user's query beyond simple keyword matching, returning results that are contextually relevant.\n",
            "Example: If a user searches for \"planets in the solar system,\" the system provides information about planets like Jupiter and Mars.\n",
            "Related Keywords: Natural Language Processing (NLP), Search Algorithms, Data Mining\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 10:\n",
            "\n",
            "HuggingFace\n",
            "Definition: HuggingFace is a library offering pre-trained models and tools for natural language processing, making NLP tasks accessible to researchers and developers.\n",
            "Example: HuggingFace's Transformers library can be used for sentiment analysis and text generation.\n",
            "Related Keywords: Natural Language Processing (NLP), Deep Learning, Library.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Load the document\n",
        "documents = TextLoader(\"./data/appendix-keywords.txt\").load()\n",
        "\n",
        "# Initialize the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "\n",
        "# Split the document into chunks\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# Initialize the retriever\n",
        "retriever = FAISS.from_documents(texts, OpenAIEmbeddings()).as_retriever(\n",
        "    search_kwargs={\"k\": 10}\n",
        ")\n",
        "\n",
        "# Define the query\n",
        "query = \"Tell me about Word2Vec.\"\n",
        "\n",
        "# Retrieve relevant documents\n",
        "docs = retriever.invoke(query)\n",
        "\n",
        "# Print the retrieved documents\n",
        "pretty_print_docs(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac736fc2",
      "metadata": {},
      "source": [
        "## Performing Re-ranking with JinaRerank\n",
        "\n",
        "- A document compression system is initialized using JinaRerank to prioritize the most relevant documents.\n",
        "\n",
        "- Retrieved documents are compressed by selecting the top 3 (top_n=3) based on relevance.\n",
        "\n",
        "- A `ContextualCompressionRetriever` is created with the JinaRerank compressor and an existing retriever.\n",
        "\n",
        "- The system processes a query to retrieve and compress relevant documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f4a2b5c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from ast import mod\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain_community.document_compressors import JinaRerank\n",
        "\n",
        "# Initialize the JinaRerank compressor\n",
        "compressor = JinaRerank(model=\"jina-reranker-v2-base-multilingual\", top_n=3)\n",
        "\n",
        "# Initialize the document compression retriever\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever\n",
        ")\n",
        "\n",
        "# Retrieve and compress relevant documents\n",
        "compressed_docs = compression_retriever.invoke(\"Explain Word2Vec.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "3b93e0a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 1:\n",
            "\n",
            "Word2Vec\n",
            "Definition: Word2Vec is a technique in NLP that maps words to a vector space, representing their semantic relationships based on context.\n",
            "Example: In a Word2Vec model, \"king\" and \"queen\" are represented by vectors located close to each other.\n",
            "Related Keywords: Natural Language Processing (NLP), Embedding, Semantic Similarity\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "Embedding\n",
            "Definition: Embedding is the process of converting textual data, such as words or sentences, into low-dimensional continuous vectors that computers can process and understand.\n",
            "Example: The word \"apple\" can be represented as a vector like [0.65, -0.23, 0.17].\n",
            "Related Keywords: Natural Language Processing (NLP), Vectorization, Deep Learning\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "VectorStore\n",
            "Definition: A VectorStore is a system designed to store data in vector format, enabling efficient retrieval, classification, and analysis tasks.\n",
            "Example: Storing word embedding vectors in a database for quick access during semantic search.\n",
            "Related Keywords: Embedding, Database, Vectorization\n"
          ]
        }
      ],
      "source": [
        "# Display the compressed documents in a readable format\n",
        "pretty_print_docs(compressed_docs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-opentutorial-6Qq4Ubg1-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
